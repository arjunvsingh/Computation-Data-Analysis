{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    \"\"\"\n",
    "    Full covariance Gaussian Mixture Model,\n",
    "    trained using Expectation Maximization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_components : int\n",
    "        Number of clusters/mixture components in which the data will be\n",
    "        partitioned into.\n",
    "\n",
    "    n_iters : int\n",
    "        Maximum number of iterations to run the algorithm.\n",
    "\n",
    "    tol : float\n",
    "        Tolerance. If the log-likelihood between two iterations is smaller than\n",
    "        the specified tolerance level, the algorithm will stop performing the\n",
    "        EM optimization.\n",
    "\n",
    "    seed : int\n",
    "        Seed / random state used to initialize the parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components: int, n_iters: int, tol: float, seed: int):\n",
    "        self.n_components = n_components\n",
    "        self.n_iters = n_iters\n",
    "        self.tol = tol\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        # data's dimensionality and responsibility vector\n",
    "        n_row, n_col = X.shape     \n",
    "        self.resp = np.zeros((n_row, self.n_components))\n",
    "\n",
    "        # initialize parameters\n",
    "        np.random.seed(self.seed)\n",
    "        chosen = np.random.choice(n_row, self.n_components, replace = False)\n",
    "        self.means = X[chosen]\n",
    "        self.weights = np.full(self.n_components, 1 / self.n_components)\n",
    "        \n",
    "        # for np.cov, rowvar = False, \n",
    "        # indicates that the rows represents obervation\n",
    "        shape = self.n_components, n_col, n_col\n",
    "        self.covs = np.full(shape, np.cov(X, rowvar = False))\n",
    "\n",
    "        log_likelihood = 0\n",
    "        self.converged = False\n",
    "        self.log_likelihood_trace = []      \n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            log_likelihood_new = self._do_estep(X)\n",
    "            self._do_mstep(X)\n",
    "\n",
    "            if abs(log_likelihood_new - log_likelihood) <= self.tol:\n",
    "                self.converged = True\n",
    "                break\n",
    "  \n",
    "            log_likelihood = log_likelihood_new\n",
    "            self.log_likelihood_trace.append(log_likelihood)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _do_estep(self, X):\n",
    "        \"\"\"\n",
    "        E-step: compute responsibilities,\n",
    "        update resp matrix so that resp[j, k] is the responsibility of cluster k for data point j,\n",
    "        to compute likelihood of seeing data point j given cluster k, use multivariate_normal.pdf\n",
    "        \"\"\"\n",
    "        self._compute_log_likelihood(X)\n",
    "        log_likelihood = np.sum(np.log(np.sum(self.resp, axis = 1)))\n",
    "\n",
    "        # normalize over all possible cluster assignments\n",
    "        self.resp = self.resp / self.resp.sum(axis = 1, keepdims = 1)\n",
    "        return log_likelihood\n",
    "\n",
    "    def _compute_log_likelihood(self, X):\n",
    "        for k in range(self.n_components):\n",
    "            prior = self.weights[k]\n",
    "            likelihood = multivariate_normal(self.means[k], self.covs[k],allow_singular=True).pdf(X)\n",
    "            self.resp[:, k] = prior * likelihood\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _do_mstep(self, X):\n",
    "        \"\"\"M-step, update parameters\"\"\"\n",
    "\n",
    "        # total responsibility assigned to each cluster, N^{soft}\n",
    "        resp_weights = self.resp.sum(axis = 0)\n",
    "        \n",
    "        # weights\n",
    "        self.weights = resp_weights / X.shape[0]\n",
    "\n",
    "        # means\n",
    "        weighted_sum = np.dot(self.resp.T, X)\n",
    "        self.means = weighted_sum / resp_weights.reshape(-1, 1)\n",
    "        # covariance\n",
    "        for k in range(self.n_components):\n",
    "            diff = (X - self.means[k]).T\n",
    "            weighted_sum = np.dot(self.resp[:, k] * diff, diff.T)\n",
    "            self.covs[k] = weighted_sum / resp_weights[k]\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('Homework 2/hw2/data/data.mat')\n",
    "images = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = images[:,0].reshape(784,1)\n",
    "X = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GMM at 0x127049790>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm = GMM(n_components = 2, n_iters = 1, tol = 1e-4, seed = 4)\n",
    "gmm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(data, means, covs, title):\n",
    "    \"\"\"visualize the gaussian components over the data\"\"\"\n",
    "    plt.figure()\n",
    "#     plt.plot(data[:, 0], data[:, 1], 'ko')\n",
    "\n",
    "    delta = 0.025\n",
    "    k = means.shape[0]\n",
    "    x = np.arange(-2.0, 7.0, delta)\n",
    "    y = np.arange(-2.0, 7.0, delta)\n",
    "    x_grid, y_grid = np.meshgrid(x, y)\n",
    "    coordinates = np.array([x_grid.ravel(), y_grid.ravel()]).T\n",
    "\n",
    "    col = ['green', 'red', 'indigo']\n",
    "    for i in range(k):\n",
    "        mean = means[i]\n",
    "        cov = covs[i]\n",
    "        z_grid = multivariate_normal(mean, cov).pdf(coordinates).reshape(x_grid.shape)\n",
    "        plt.contour(x_grid, y_grid, z_grid, colors = col[i])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (129600,2) and (1,1) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fa290dec688a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Initial clusters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-9178d5a94257>\u001b[0m in \u001b[0;36mplot_contours\u001b[0;34m(data, means, covs, title)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mz_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mlogpdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_quantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         out = self._dist._logpdf(x, self.mean, self.cov_info.U,\n\u001b[0;32m--> 746\u001b[0;31m                                  self.cov_info.log_pdet, self.cov_info.rank)\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_squeeze_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_logpdf\u001b[0;34m(self, x, mean, prec_U, log_det_cov, rank)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \"\"\"\n\u001b[1;32m    469\u001b[0m         \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mmaha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec_U\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_LOG_2PI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_det_cov\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (129600,2) and (1,1) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_contours(X, gmm.means, gmm.covs, 'Initial clusters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x125b36a90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(vec.reshape(28,28).T,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gmm.resp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126bcb510>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a.reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-367.1395733377357]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.log_likelihood_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.mean(gmm.resp,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm.resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "       0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
